{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c1346-05ad-4626-b236-1b628f110bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "from pyLDAvis import prepare\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import MeCab\n",
    "nltk.download('wordnet')\n",
    "import matplotlib.pyplot as plt  # max_iterの適切な値を見極めるために必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc032a0-f2c5-45bc-aac7-7f7eb3684340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルからデータを読み込む\n",
    "with open('text.txt', 'r', encoding='utf-8') as f:#テキストファイルの名前を入れる\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f1006-6b9c-44af-8a73-9e3d52f6c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト前処理を行う\n",
    "exclude = set(string.punctuation)\n",
    "m = MeCab.Tagger(\"-Owakati\")  # MeCabを使って日本語テキストを分かち書き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7296b-8813-4e43-93a2-920a799448f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定の文章を取り除く条件を設定\n",
    "#keywords_to_remove = [\" \", \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29a6ce-f393-42f4-9ce1-86ccefb96fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定の文章を取り除く\n",
    "#lines = [line for line in lines if all(keyword not in line for keyword in keywords_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0b332-3895-42c0-ae8a-65149c6f5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    punc_free = ''.join(ch for ch in doc if ch not in exclude)\n",
    "    no_digits = re.sub(r'\\d+', '', punc_free)  # 数字を削除する\n",
    "    no_alpha = re.sub(r'[a-zA-Z]+', '', no_digits)  # 英字を削除する\n",
    "    normalized = m.parse(no_alpha).strip()\n",
    "    return normalized\n",
    "lines = [clean(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87892df0-af34-4c5f-b9e9-9bba4fcae1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文書-単語行列の作成\n",
    "vect = CountVectorizer(max_df=1.0, stop_words=None)#1.0なら全て\n",
    "data = vect.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e7dc5-6977-4f79-864c-3cc80e60767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適なパラメータでLDAの適用と学習\n",
    "lda = LatentDirichletAllocation(n_components=8,#トピックの数\n",
    "                                max_iter=40,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=10,#デフォルト\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f831a22d-893e-48ce-a50d-6c15bab2c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvisを用いた可視化\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0248b1-5ebe-4361-8b82-39e092e99bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なデータを取得\n",
    "topic_term_dists = lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]  # 各トピックの単語分布\n",
    "doc_topic_dists = lda.transform(data)  # 各文書のトピック分布\n",
    "term_frequency = data.sum(axis=0).A1  # 各単語の出現回数\n",
    "vocab = vect.get_feature_names_out()  # 単語リスト\n",
    "doc_lengths = data.sum(axis=1).A1  # 各文書の単語数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46a90c-bec1-46b3-b661-089a1bbe98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.prepare 関数でデータを可視化形式に変換\n",
    "panel = pyLDAvis.prepare(\n",
    "    topic_term_dists=topic_term_dists,\n",
    "    doc_topic_dists=doc_topic_dists,\n",
    "    doc_lengths=doc_lengths,\n",
    "    vocab=vocab,\n",
    "    term_frequency=term_frequency,\n",
    "    mds='tsne'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfc4eb-c8ee-4c58-9276-76499b4fc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を表示\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190373c-7083-4458-99d2-e90ad2f9ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここからは任意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1fafe-d7d8-42e9-afd9-c0a9f8cc05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#最適なlearning_offsetの値をグラフから探る\n",
    "likelihoods = []\n",
    "max_iters_range = range(1, 50)#適切な値を探る\n",
    "\n",
    "for max_iter in max_iters_range:\n",
    "    lda = LatentDirichletAllocation(n_components=8, max_iter=max_iter,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=10,\n",
    "                                    random_state=0)\n",
    "    lda.fit(data)\n",
    "    likelihood = lda.score(data)\n",
    "    likelihoods.append(likelihood)\n",
    "\n",
    "# 学習曲線をプロット\n",
    "plt.plot(max_iters_range, likelihoods, marker='o')\n",
    "plt.xlabel('max_iter')\n",
    "plt.ylabel('Log Likelihood')\n",
    "plt.title('LDA Learning Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb968f5-bf35-4bb2-86a8-fca6b174ee4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
